{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# Define CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define CNN model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # CIFAR-10 ‚Üí 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "net = NeuralNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(30):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1} Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Save model\n",
    "torch.save(net.state_dict(), 'trained_net.pth')\n",
    "\n",
    "# Reload model for evaluation\n",
    "net.load_state_dict(torch.load('trained_net.pth'))\n",
    "net.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'‚úÖ Accuracy on test images: {accuracy:.2f}%')\n",
    "\n",
    "# Image transformation for custom image prediction\n",
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Predict on external images\n",
    "image_paths = [\n",
    "    '../images/image1.jpg',\n",
    "    '../images/image2.jpg',\n",
    "]\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for path in image_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"‚ö†Ô∏è Image not found: {path}\")\n",
    "            continue\n",
    "        img_tensor = load_image(path).to(device)\n",
    "        output = net(img_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        print(f'üñºÔ∏è {os.path.basename(path)} ‚Üí Predicted: {class_names[pred.item()]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bcdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "print(\"Starting script execution\")\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Torch installation location:\", torch.__file__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Defining CIFAR-100 class names\")\n",
    "class_names = [f\"class_{i}\" for i in range(100)]  # CIFAR-100 has 100 classes\n",
    "\n",
    "print(\"Setting up data transformations\")\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "print(\"Loading CIFAR-100 dataset\")\n",
    "train_data = torchvision.datasets.CIFAR100(root='./data', train=True, transform=train_transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "print(\"Creating data loaders\")\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(\"Defining ResidualBlock class\")\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"Executing ResidualBlock forward pass\")\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "print(\"Defining NeuralNet class\")\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Initializing NeuralNet layers\")\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self.make_layer(64, 64, 2)\n",
    "        self.layer2 = self.make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(128, 256, 2, stride=2)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256, 100)  # CIFAR-100 has 100 classes\n",
    "\n",
    "    def make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
    "        print(f\"Creating layer with {blocks} blocks, in_channels={in_channels}, out_channels={out_channels}, stride={stride}\")\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Executing NeuralNet forward pass\")\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "print(\"Instantiating model\")\n",
    "net = NeuralNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "print(\"Starting training loop\")\n",
    "for epoch in range(50):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"Starting epoch {epoch+1}\")\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        print(f\"Processing batch {i+1}/{len(train_loader)} in epoch {epoch+1}\")\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch+1} Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "print(\"Saving model\")\n",
    "torch.save(net.state_dict(), 'cifar100_net.pth')\n",
    "\n",
    "print(\"Reloading model for evaluation\")\n",
    "net.load_state_dict(torch.load('cifar100_net.pth'))\n",
    "net.eval()\n",
    "\n",
    "print(\"Starting evaluation on test set\")\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        print(f\"Evaluating batch {i+1}/{len(test_loader)}\")\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test images: {accuracy:.2f}%')\n",
    "\n",
    "print(\"Setting up transform for custom image prediction\")\n",
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    print(f\"Loading image: {image_path}\")\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_paths = [\n",
    "    '../images/image1.jpg',\n",
    "    '../images/image2.jpg',\n",
    "]\n",
    "\n",
    "print(\"Starting prediction on external images\")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for path in image_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Image not found: {path}\")\n",
    "            continue\n",
    "        img_tensor = load_image(path).to(device)\n",
    "        print(f\"Predicting for {os.path.basename(path)}\")\n",
    "        output = net(img_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        print(f'{os.path.basename(path)} predicted as class {pred.item()}')\n",
    "\n",
    "print(\"Script execution completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
